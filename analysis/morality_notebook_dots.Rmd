---
title: "Morality in the time of cognitive famine - Dots task"
author: Jonas Kristoffer LindelÃ¸v
date: December, 2018

output:
  github_document:
    toc: true
---


# About
This is part of the analysis that accompanies the paper "Morality in the time of cognitive famine" by Panos, Jonas, Michaela, and others. You are now looking at the analysis of **experiment 3 and 4** using the Dots Task to study cheating. 



# Setting up
Load appropriate stuff:
```{r setup, results=FALSE, message=FALSE, warning=FALSE}
library(car)  # For some of the logistic regressions
library(tidyverse)
library(lme4)
library(kableExtra)

source('misc/functions utility.R')
source('misc/functions inference.R')  # Contains LRT and LRT_binom
```

You could redo the preprocessing of the original data if you wanted to. It saves the data.frames which are loaded in the sections below.
```{r, eval=FALSE}
source('preprocess dots.R')
```


```{r}
D_dots = readRDS('data/dots.Rda')
D_dots = droplevels(subset(D_dots, condition == 'experiment'))  # Not practice, etc
D_dots = select(D_dots, -encode, -equationCorrect, -equationScores, -equationRTs, -recallAns, -equationAnss)  # Tidyr doesn't like these matrix columns and we won't
D = D_dots  # For convenience
```



# Descriptives
```{r dots descriptives}
# Just one row per subject to do descriptives on them
D_id = D[!duplicated(D$id), ]

# Per-group descriptives for paper
D_id %>%
  group_by(exp) %>%
  summarise(n=n(),
            age_years = sprintf('%.1f (%.1f)', mean(age), sd(age)),
            males = sprintf('%i (%.1f %%)', sum(gender=='male'), 100*sum(gender=='male')/n())) #%>%
  #kable() %>% 
  #kable_styling(bootstrap_options = "striped", full_width = F)


# Supplementary table: stratified by level and stimType descriptives
x = D_id %>%  # Per-person
  group_by(stimType, level) %>%
  summarise(n=n(),
            males = sprintf('%i (%.1f %%)', sum(gender=='male'), 100*sum(gender=='male')/n()),
            age_years = sprintf('%.1f (%.1f)', mean(age), sd(age)))

y = D %>%  # All trials
  group_by(stimType, level) %>%
  summarise(arithmetic = sprintf('%.1f%%', mean(equationCorrectness)*100),
            recall = sprintf('%.1f%%', mean(recallProportion)*100))

bind_cols(x, y[,3:4]) #%>%
  #kable() %>% 
  #kable_styling(bootstrap_options = "striped", full_width = F)
```



# WM Load and dots: Figure 4 and supplementary
```{r figure4, cache=TRUE}
# Span and correctness
D$levelGroup = ifelse(D$level == '1-7', 'span 1-7', 'span 1-3, 3-5, 5-7')
D$levelGroup = factor(D$levelGroup, levels=c('span 1-7', 'span 1-3, 3-5, 5-7'))
D$incentiveLevel = with(D, interaction(dotsIncentive, level))

# The figure
# Note that binom.summary is one I made to do binomial CIs.
figure4 = ggplot(D, aes(x=span, y=dotsCorrect, color=dotsIncentive, group=incentiveLevel)) + 
  stat_summary(fun.data=binom.summary, size=0.3, position=position_dodge(0.5)) + 
  stat_summary(fun.y=mean, geom='line', position=position_dodge(0.5)) +
  #binomial_smooth(size=0.5) +
  
  # Styling
  geom_hline(aes(yintercept=0.5), color='red', lty=2) +
  scale_x_continuous(breaks=1:7) + scale_y_continuous(breaks=seq(-1, 1, 0.1 )) + 
  coord_cartesian(ylim=c(0.4, 1)) + 
  
  # Faceting
  facet_grid(levelGroup~dotsReceiver) +
  
  # Labels
  labs(title='WM load and cheating', y='Correctness', x='Complex Span')

# More styling
figure4 = style_my_plot(figure4) + 
   scale_colour_manual(values=c('black', '#777777'))
  
# Save and plot it
ggsave('figures/Figure 4 - Dots and CS span.png', figure4, width=7, height=7, units='cm', dpi=300, scale=1.7)
figure4
```


Supplementary figure - adds `dotsN` and `stimType` to the faceting:
```{r}
figure4S = ggplot(D, aes(x=span, y=dotsCorrect, color=dotsIncentive)) + 
  stat_summary(fun.data=binom.summary, size=0.3, position=position_dodge(0.5)) + 
  stat_summary(fun.y=mean, geom='line', position=position_dodge(0.5)) +
  
  # Styling
  geom_hline(aes(yintercept=0.5), color='red', lty=2) +
  scale_x_continuous(breaks=1:7) + scale_y_continuous(breaks=seq(-1, 1, 0.1 )) + 
  coord_cartesian(ylim=c(0.25, 1)) + 
  labs(title='WM load and cheating', y='Correctness', x='Complex Span') +
  
  # Layout
  facet_grid(dotsN ~ stimType + dotsReceiver)

# More styling
figure4S = style_my_plot(figure4S) + 
  scale_colour_manual(values=c('black', '#777777'))

# Save it and show it here
ggsave('figures/Figure 4S - Dots and CS span.png', figure4S, width=9, height=9, units='cm', dpi=300, scale=1.7)
figure4S
```



# WM load and dots: inferential stuff
There is a tradeoff to be made in the models below between having a full random structure and making the models identifiable. I have tried keeping the model fairly maximal but varified that simpler models yield the same qualitative conclusions. One simplification is not to include a random effect for (id|level) and (id|stimType) since the random effect for id does most of the job of between-group differences. So the random structure reflects within-subject structures below.


Do subjects cheat? dotsIncentive makes this a difference-question between cheating and accuracy

Notice that the reference level becomes quite a specific combination of the fixed effects, but we are only interested in the effects, not the intercept, so that's OK.
```{r binom incentive, warning=FALSE, cache=TRUE}
LRT_binom(D,
          dotsCorrect ~ dotsIncentive + dotsReceiver + stimType + dotsN + time_hours + (span|id),
          dotsCorrect ~                 dotsReceiver + stimType + dotsN + time_hours + (span|id))
```

Is cheating (the accuracy-cheating difference) modulated by receiver?
```{r binom incentive-receiver, warning=FALSE, cache=TRUE}
LRT_binom(D,
          dotsCorrect ~ dotsIncentive * dotsReceiver + dotsN + time_hours + (span|id),
          dotsCorrect ~ dotsIncentive + dotsReceiver + dotsN + time_hours + (span|id))
```


Is cheating (the accuracy-cheating difference) modulated by CS span?
```{r binom incentive-span, warning=FALSE, cache=TRUE}
LRT_binom(subset(D, dotsReceiver == 'Self'),
          dotsCorrect ~ dotsIncentive*span + dotsN + time_hours + (1|id),
          dotsCorrect ~ dotsIncentive+span + dotsN + time_hours + (1|id))
LRT_binom(subset(D, dotsReceiver == 'Other'),
          dotsCorrect ~ dotsIncentive*span + dotsN + time_hours + (1|id),
          dotsCorrect ~ dotsIncentive+span + dotsN + time_hours + (1|id))

```


Does this cheating-span relationship replicate across dotsN (dots ambiguity)?
```{r binom incentive-span-dotsN, warning=FALSE, cache=TRUE}
LRT_binom(D,
          dotsCorrect ~ dotsIncentive*span*dotsN + dotsReceiver + time_hours + (1|id),
          dotsCorrect ~ dotsIncentive*span*dotsN + dotsReceiver + time_hours + (1|id) - dotsIncentive:span:dotsN)

```


Is this relationship different for different stimulus types?
```{r binom incentive-span-type, warning=FALSE, cache=TRUE}
LRT_binom(D,
          dotsCorrect ~ dotsIncentive*span*stimType + dotsN + (1|id),
          dotsCorrect ~ dotsIncentive*span*stimType + dotsN + (1|id) - dotsIncentive:span:stimType)

```



# Prepare for depletion analyses
Before we dive into time-effects, we'll make a data.frame called `D_time` which excludes subjects who completed before the time window of interest for depletion - and optionally those who were very slow. For the latter, you could think that they were relaxed (not depleted) OR slowed by depletion itself, so we think that it is ambiguous.

```{r dots depletion prep}
time_frame_lower = 45 * 60  # Which time frame to analyze. Try setting to 60 minutes.
time_frame_upper = 100 * 60  # Not used in paper, but feel free to use it here.

# Select subjects for analysis: only those who did not complete prematurely
completion_data = aggregate(time_secs~id, D, FUN=max)  # Vector of completion times
ids_fast = completion_data$id[completion_data$time_secs < time_frame_lower]
ids_slow = completion_data$id[completion_data$time_secs > time_frame_upper]
D_time = subset(D, !id %in% ids_fast & !id %in% ids_slow)

# Tell what's happening and how many were excluded
sprintf('M=%.02f minutes (SD=%.02f). %i excluded out of %i', 
        mean(completion_data$time_secs)/60, 
        sd(completion_data$time_secs)/60,
        length(ids_slow) + length(ids_fast), nrow(completion_data))

# Visualize what happened :-)
plot(sort(completion_data$time_secs)/60, ylim=c(20, 110), xlab='Participant (ordered)', ylab='Completion time (minutes)', main='Window of acceptance for completion times'); grid(); abline(h=c(time_frame_lower/60, time_frame_upper/60), col='red')

# One subject has wrong/absent recording of trial time, so is not included
D_time = subset(D_time, !is.na(D_time$utc_start))
```



# Depletion and dots: figure 5 and supplementary
For main text:
```{r figure5, cache=TRUE, fig.height=8, fig.width=5}
figure5 = ggplot(D_time, aes(x=time_secs/60, y=dotsCorrect, color=dotsIncentive, shape=dotsIncentive)) + 
  stat_summary_bin(fun.y=mean, geom='point', binwidth=4, size=1.5) + 
  binomial_smooth(size=0.5) +
  #stat_smooth(method='loess', geom='line', span=1) + 
  #stat_summary_bin(fun.data=binom.summary, binwidth=10, position=position_dodge(3), size=0.3) +
  #binomial_smooth(formula = y ~ splines::ns(x, 2)) +
  
  # Layout
  facet_grid(level~dotsReceiver) + 
  
  # Styling
  geom_hline(aes(yintercept=0.5), color='red', lty=2) +
  coord_cartesian(xlim=c(0, 46), ylim=c(0.35, 1)) +
  scale_x_continuous(breaks=seq(0, 100, 10)) + 
  scale_y_continuous(breaks=seq(0,1,0.1), labels=paste(seq(0, 1, 0.1)*100, '%', sep='')) +
  
  labs(title='Depletion and cheating', y='Correctness', x='Minutes elapsed')

# Style it a bit more
figure5 = style_my_plot(figure5) + 
  scale_colour_manual(values=c('black', '#777777'))

# Save it and show it here
ggsave('figures/Figure 5 - Dots and depletion.png', figure5, width=5, height=7.5, units='cm', dpi=300, scale=2.5)
figure5
```


For the supplementary materials:
```{r figure5S, cahce=TRUE, fig.height=6, fig.width=8}
# SUPPLEMENTARY
figureS5 = ggplot(D, aes(x=time_secs/60, y=dotsCorrect, color=dotsIncentive)) + 
  #stat_summary_bin(geom='line', fun.y=mean, binwidth=1) +
  #stat_smooth(method='loess', geom='line', span=1) + 
  #stat_summary_bin(fun.data=binom.summary, binwidth=10, position=position_dodge(3), size=0.3) +
  stat_summary_bin(fun.y=mean, geom='point', binwidth=10, size=1.5) + 
  binomial_smooth(size=0.5) +
  
  # Layout
  facet_grid(level ~ dotsReceiver + dotsN) + 
  
  # Styling
  geom_hline(aes(yintercept=0.5), color='red', lty=2) +
  coord_cartesian(xlim=c(0, 60), ylim=c(0.35, 1)) +
  scale_x_continuous(breaks=seq(0, 100, 15)) + 
  scale_y_continuous(breaks=seq(0,1,0.1), labels=paste(seq(0, 1, 0.1)*100, '%', sep='')) + 
  
  labs(title='Depletion and cheating', y='Correctness', x='Minutes elapsed')

figureS5 = style_my_plot(figureS5) + 
  scale_colour_manual(values=c('black', '#777777'))
ggsave('figures/Figure S5 - Dots and depletion.png', figureS5, width=9, height=4, units='cm', dpi=300, scale=2)

figureS5
```



# Depletion analysis
`dotsIncentive` marks the difference between accuracy and cheat-inventive trials; i.e. the magnitude of cheating. time_hours is the time passed since first trial, scaled to facilitate identifiability in the model. The random effects structure captures some known design features on which shrinkage would be nice.
* `dotsN` is fixed because we do not consider them to be drawn randomly from a larger possible number of dots and therefore do not want shrinkage of extreme N.
* `stimType` is random because we think there could be many different kinds of stimuli which would show the same pattern.
* slopes are random for each subject. We think that there should be shrinkage to an overall time-trend.
* There is also a random offset for each subject; reflecting good/bad days, I guess.

Is there a time-effect of the cheat-incentive overall?
```{r binom time-incentive, warning=FALSE, cache=TRUE}
LRT_binom(D_time,
          dotsCorrect ~ time_hours*dotsIncentive + dotsN + dotsReceiver + (span|id),
          dotsCorrect ~ time_hours+dotsIncentive + dotsN + dotsReceiver + (span|id))
```


Is there a cognitive depletion on the ability to do the task?
```{r binom time-incentive specific, warning=FALSE, cache=TRUE}
LRT_binom(subset(D_time, dotsIncentive == 'accuracy'),
          dotsCorrect ~ time_hours + dotsN + dotsReceiver + (span|id),
          dotsCorrect ~          1 + dotsN + dotsReceiver + (span|id))

LRT_binom(subset(D_time, dotsIncentive == 'cheat'),
          dotsCorrect ~ time_hours + dotsN + dotsReceiver + (span|id),
          dotsCorrect ~          1 + dotsN + dotsReceiver + (span|id))
```


Do the different difficulty levels cause different depletion?
```{r binom time-incentive-level, warning=FALSE, cache=TRUE}
D_time$level_numeric = as.numeric(D_time$level)  # Numeric to make it ordered according to the hypothesis
LRT_binom(subset(D_time, level_numeric != 4),  # Leave out the mixed group (1-7)
          dotsCorrect ~ time_hours*dotsIncentive*level_numeric + dotsN + dotsReceiver + (span|id),
          dotsCorrect ~ time_hours*dotsIncentive*level_numeric + dotsN + dotsReceiver + (span|id) - time_hours:dotsIncentive:level_numeric)
```


Does perceived depletion alter the observed slope change?
```{r binom time-incentive-subjective, warning=FALSE, cache=TRUE}
LRT_binom(subset(D_time, !is.na(subjectiveDepletion)),
          dotsCorrect ~ time_hours*dotsIncentive*subjectiveDepletion + dotsN + dotsReceiver + (span|id),
          dotsCorrect ~ time_hours*dotsIncentive*subjectiveDepletion + dotsN + dotsReceiver + (span|id) - time_hours:dotsIncentive:subjectiveDepletion)
```


Is the time-trend on cheating different for self- and other-receivers?
```{r binom time-incentive-receiver, warning=FALSE, cache=TRUE}
LRT_binom(D_time,
          dotsCorrect ~ time_hours*dotsIncentive*dotsReceiver + dotsN + (span|id),
          dotsCorrect ~ time_hours*dotsIncentive*dotsReceiver + dotsN + (span|id) - time_hours:dotsIncentive:dotsReceiver)
```


# Supplementary stuff

## A validity check: Equation correctness and reaction time
(see the notebook on PGG for this)
An important part of the complex span task is that subjects engage in the processing task, thereby preventing chunking- or rehearsal strategies. We provided a monetary incentive to do the processing task correctly. 

Still, it is possible that some subjects would prioritize it lower in order to improve recall, and such behavior would undermine the purpose of using a complex span task, making it more like a simple forward letter span task.

We considered what indices would reveal such behavior. A priori, it is hard to distinguish between poor math skills and laziness. Similarly, it is difficult to distinguish between being a low-span subject or just not investing an effort to encode the items. 

However, short reaction times in combination with low accuracy would be one such index: poor performance and no effort (time) to improve it. We show the data for the equation tasks descriptively below using violin plots with 25% and 75% quartiles as well as (horizontally) jittered data.

Across tasks (PGG and Dots) and span levels (1-7), for all correctness levels where there is a considerable amount of data, the reaction times are highly similar. Only for correctness levels with very little data do we observe deviations from this, likely due to noise. We conclude that, to the best of our knowledge, the task was succesful in engaging subjects in processing.

FIrst, let's load the PGG data in here:

```{r load data}
# Load the data.frame (not in csv because the matrix columns would be lost)
D_pgg = readRDS('data/pgg.Rda')
D_pgg = subset(D_pgg, condition=='experiment')  # Remove practice, etc.
D_pgg = select(D_pgg, -encode, -equationCorrect, -equationScores, -equationRTs, -recallAns, -equationAnss)  # Tidyr doesn't like these matrix columns and we won't be using them
D_pgg = droplevels(D_pgg)
```

And merge the data together:
```{r}
D_all = plyr::rbind.fill(D_dots, D_pgg)  # All together now!
D_all$task = ifelse(D_all$exp %in% c(1,2), 'PGG', 'Dots')
```


Now, for the actual analysis:
```{r}
fit = lmer(dotsRT ~ level + stimType + (1|id), subset(D, exp==4))

#D.plot = subset(D_all, 
ggplot(subset(D_all, equationRT < 10), aes(x=factor(round(equationCorrectness*100)), y=equationRT)) + 
  #stat_summary(fun.data=mean_cl_boot) + 
  geom_jitter(width=0.3, height=0, alpha=0.2) +   # Only jitter width
  geom_violin(draw_quantiles = c(0.25, 0.75), alpha=0.5, scale='width') + 
  facet_grid(task~span, scales='free') + 
  #coord_cartesian(ylim=c(0, 7)) + 
  labs(x='Correctness', y='Reaction time', title='Equation performance') + 
  #scale_x_continuous(breaks= scales::pretty_breaks()) +
  theme_bw(13)

# TODO: Methods: RT for PGG
#fit = lmer(pggRT ~ level + stimType + (1|id), subset(D, exp==2))

```



## Percieved load (questionnaire data)
Mostly for exploratory reasons, we did ask subjects how they perceived the task with respect to frustration, stress, effort, difficulty, and satisfaction. Here, we explore whether subjects "felt" the difference in load. 

First, we turn to Experiment 2 and the Public Goods Game. The estimated differences between difficulty levels is very small (around 0.3) on a scale with range 6. If ignoring this quantitative observation, the effect seems to be that as you get to span 4 and above, the perceived load is constant.

Again we see very small correspondences when considering the range-6 scale, but a large degree of the probability density is towards positive values.

```{r supplementary questionnaire level, cache=T, message=F, warning=F}
perceived_load_cols = c('qStress', 'qDifficulty', 'qFrustration', 'qEffort', 'qSatisfied')

# Summarise per subject
D_id_dots = D_dots %>%
  mutate(qSatisfied = 1 + (7 - qSatisfied),  # Same direction as other questions
         perceived_load = rowMeans(select(D_dots, perceived_load_cols))) %>%  # Mean of load ratings
  group_by(id, level) %>%
  filter(dotsReceiver=='Self' & dotsIncentive == 'cheat') %>%
  summarise(dotsCorrect = mean(dotsCorrect, na.rm=T),
            perceived_load = mean(perceived_load))

# Plot the relationship
ggplot(D_id_dots, aes(x=level, y=perceived_load)) + 
  geom_violin(draw_quantiles = c(0.25, 0.5, 0.75)) + 
  geom_jitter(width=0.2, height=0) +
  labs(x = 'Difficulty level (span)', y='Perceived load', title='Do participants perceive the objective load?')
```

Test it inferentially:
```{r supplementary brm perceived1, cache=TRUE}
library(brms)
D.analyse.dots = filter(D_id_dots, level !='1-7' & !is.na(perceived_load))  # ... and no NA data
result_level_dots = brm(perceived_load ~ level, D.analyse.dots)  # Quick: just run with the defaults
plot(result_level_dots, pars='^b_')
```


... and now for degree of cheating:

```{r supplementary questionnaire invest, cache=T, message=F, warning=F}
# Plot it
ggplot(D_id_dots, aes(x=dotsCorrect, y=perceived_load)) + 
  geom_point() +
  geom_smooth(method='lm') +
  labs(x='Dots correctness', y='Perceived load', title='Do participants cheat based on perceived load?')
```

Test it inferentially:
```{r supplementary brm perceived2, cache=TRUE}
# Inferentially
result_cheat_dots = brm(perceived_load ~ dotsCorrect, D.analyse.dots)  # Simple linear regression
plot(result_cheat_dots, pars='b_dotsCorrect')
```